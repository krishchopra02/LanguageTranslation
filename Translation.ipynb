{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport string\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow_probability as tfp\nimport time","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-17T15:43:55.620739Z","iopub.execute_input":"2022-07-17T15:43:55.621077Z","iopub.status.idle":"2022-07-17T15:44:03.492809Z","shell.execute_reply.started":"2022-07-17T15:43:55.620983Z","shell.execute_reply":"2022-07-17T15:44:03.491640Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Load the dataset","metadata":{}},{"cell_type":"code","source":"dataset = pd.read_csv('../input/language-translation-englishfrench/eng_-french.csv')\ndataset.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-17T15:44:03.500708Z","iopub.execute_input":"2022-07-17T15:44:03.503839Z","iopub.status.idle":"2022-07-17T15:44:03.985415Z","shell.execute_reply.started":"2022-07-17T15:44:03.503801Z","shell.execute_reply":"2022-07-17T15:44:03.983392Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"## Size of dataset\ndataset.shape","metadata":{"execution":{"iopub.status.busy":"2022-07-17T15:44:03.986820Z","iopub.execute_input":"2022-07-17T15:44:03.987306Z","iopub.status.idle":"2022-07-17T15:44:03.994987Z","shell.execute_reply.started":"2022-07-17T15:44:03.987268Z","shell.execute_reply":"2022-07-17T15:44:03.993668Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Visualizing the length of sequences\neng = []\nfra = []\nfor i in range(dataset.shape[0]):\n    eng.append(len(dataset.iloc[i,0].split(' ')))\n    fra.append(len(dataset.iloc[i,1].split(' ')))\nlengths= pd.DataFrame({'English':eng,'French':fra})\nlengths.hist(bins=20)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-17T15:44:03.998432Z","iopub.execute_input":"2022-07-17T15:44:03.999625Z","iopub.status.idle":"2022-07-17T15:44:15.074846Z","shell.execute_reply.started":"2022-07-17T15:44:03.999587Z","shell.execute_reply":"2022-07-17T15:44:15.073929Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Preprocess dataset","metadata":{}},{"cell_type":"code","source":"def convert_lower(text):\n    # Convert text to lowercase\n    text  = text.lower()\n    return text","metadata":{"execution":{"iopub.status.busy":"2022-07-17T15:44:15.077215Z","iopub.execute_input":"2022-07-17T15:44:15.078255Z","iopub.status.idle":"2022-07-17T15:44:15.083199Z","shell.execute_reply.started":"2022-07-17T15:44:15.078215Z","shell.execute_reply":"2022-07-17T15:44:15.082303Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def remove_punctuation(text):\n    return text.translate(str.maketrans('','',string.punctuation))\n","metadata":{"execution":{"iopub.status.busy":"2022-07-17T15:44:15.085724Z","iopub.execute_input":"2022-07-17T15:44:15.086552Z","iopub.status.idle":"2022-07-17T15:44:15.095719Z","shell.execute_reply.started":"2022-07-17T15:44:15.086523Z","shell.execute_reply":"2022-07-17T15:44:15.094640Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def preprocess(text):\n    text = convert_lower(text)\n    return remove_punctuation(text)","metadata":{"execution":{"iopub.status.busy":"2022-07-17T15:44:15.097700Z","iopub.execute_input":"2022-07-17T15:44:15.098199Z","iopub.status.idle":"2022-07-17T15:44:15.104308Z","shell.execute_reply.started":"2022-07-17T15:44:15.098163Z","shell.execute_reply":"2022-07-17T15:44:15.103168Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def tokenize_text_word_wise(text):\n        tokenizer = tf.keras.preprocessing.text.Tokenizer()\n        tokenizer.fit_on_texts(text)\n        return tokenizer","metadata":{"execution":{"iopub.status.busy":"2022-07-17T15:44:15.105702Z","iopub.execute_input":"2022-07-17T15:44:15.106051Z","iopub.status.idle":"2022-07-17T15:44:15.113656Z","shell.execute_reply.started":"2022-07-17T15:44:15.106004Z","shell.execute_reply":"2022-07-17T15:44:15.112763Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Encoding and padding sequences\ndef encode(tokenizer,length,text):\n    sequence = tokenizer.texts_to_sequences(text)\n    sequence = tf.keras.preprocessing.sequence.pad_sequences(sequence,maxlen=length,padding='post')\n    return sequence","metadata":{"execution":{"iopub.status.busy":"2022-07-17T15:44:15.115214Z","iopub.execute_input":"2022-07-17T15:44:15.115549Z","iopub.status.idle":"2022-07-17T15:44:15.122214Z","shell.execute_reply.started":"2022-07-17T15:44:15.115517Z","shell.execute_reply":"2022-07-17T15:44:15.121200Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def positional_encoding(position,d):\n    rate =  1/np.power(10000,(2*((np.arange(d)[np.newaxis,:])//2))/np.float32(d))\n    angles = np.arange(position)[:,np.newaxis]*rate\n    angles[:,0::2] =  np.sin(angles[:,0::2])\n    angles[:,1::2] =  np.cos(angles[:,1::2])\n    encod= angles[np.newaxis,...]\n    return tf.cast(encod,dtype=tf.float32)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-07-17T15:44:15.127181Z","iopub.execute_input":"2022-07-17T15:44:15.127424Z","iopub.status.idle":"2022-07-17T15:44:15.134595Z","shell.execute_reply.started":"2022-07-17T15:44:15.127402Z","shell.execute_reply":"2022-07-17T15:44:15.133478Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"## Example of positional encoding\npos = positional_encoding(512,32)\nprint(pos.shape)","metadata":{"execution":{"iopub.status.busy":"2022-07-17T15:44:15.136367Z","iopub.execute_input":"2022-07-17T15:44:15.136705Z","iopub.status.idle":"2022-07-17T15:44:17.261824Z","shell.execute_reply.started":"2022-07-17T15:44:15.136673Z","shell.execute_reply":"2022-07-17T15:44:17.260963Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"## Showing a  preprocessing of english text\ndataset.iloc[:,0] = dataset.iloc[:,0].apply(preprocess)\neng_tokenizer = tokenize_text_word_wise(dataset.iloc[:,0])\neng_vocab_length  = len(eng_tokenizer.word_index)+1\ndataset.iloc[:,0].head()","metadata":{"execution":{"iopub.status.busy":"2022-07-17T15:44:17.264056Z","iopub.execute_input":"2022-07-17T15:44:17.264714Z","iopub.status.idle":"2022-07-17T15:44:19.798944Z","shell.execute_reply.started":"2022-07-17T15:44:17.264673Z","shell.execute_reply":"2022-07-17T15:44:19.798002Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"print(f'English vocab length {eng_vocab_length}')","metadata":{"execution":{"iopub.status.busy":"2022-07-17T15:44:19.800344Z","iopub.execute_input":"2022-07-17T15:44:19.800695Z","iopub.status.idle":"2022-07-17T15:44:19.806151Z","shell.execute_reply.started":"2022-07-17T15:44:19.800660Z","shell.execute_reply":"2022-07-17T15:44:19.805192Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"## Showing a  preprocessing of French text\ndataset.iloc[:,1] = dataset.iloc[:,1].apply(preprocess)\nfra_tokenizer = tokenize_text_word_wise(dataset.iloc[:,1])\nfra_vocab_length  = len(fra_tokenizer.word_index)+1\ndataset.iloc[:,1].head()","metadata":{"execution":{"iopub.status.busy":"2022-07-17T15:44:19.807516Z","iopub.execute_input":"2022-07-17T15:44:19.808095Z","iopub.status.idle":"2022-07-17T15:44:22.989412Z","shell.execute_reply.started":"2022-07-17T15:44:19.808059Z","shell.execute_reply":"2022-07-17T15:44:22.988316Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"print(f'French vocab length {fra_vocab_length}')","metadata":{"execution":{"iopub.status.busy":"2022-07-17T15:44:22.990998Z","iopub.execute_input":"2022-07-17T15:44:22.991392Z","iopub.status.idle":"2022-07-17T15:44:22.996403Z","shell.execute_reply.started":"2022-07-17T15:44:22.991348Z","shell.execute_reply":"2022-07-17T15:44:22.995444Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"X = encode(eng_tokenizer,10,dataset.iloc[:,0])\nY = encode(fra_tokenizer,10,dataset.iloc[:,1])\n","metadata":{"execution":{"iopub.status.busy":"2022-07-17T15:44:22.997790Z","iopub.execute_input":"2022-07-17T15:44:22.998359Z","iopub.status.idle":"2022-07-17T15:44:28.568187Z","shell.execute_reply.started":"2022-07-17T15:44:22.998324Z","shell.execute_reply":"2022-07-17T15:44:28.567184Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# some examples\nprint(X[:10])","metadata":{"execution":{"iopub.status.busy":"2022-07-17T15:44:28.569671Z","iopub.execute_input":"2022-07-17T15:44:28.570044Z","iopub.status.idle":"2022-07-17T15:44:28.577435Z","shell.execute_reply.started":"2022-07-17T15:44:28.569992Z","shell.execute_reply":"2022-07-17T15:44:28.575837Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## Building model","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrainX,testX,trainY,testY = train_test_split(X,Y,test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2022-07-17T15:44:28.578720Z","iopub.execute_input":"2022-07-17T15:44:28.579196Z","iopub.status.idle":"2022-07-17T15:44:28.705543Z","shell.execute_reply.started":"2022-07-17T15:44:28.579157Z","shell.execute_reply":"2022-07-17T15:44:28.704549Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"BUFFER_SIZE= 200000\nBATCH_SIZE = 128","metadata":{"execution":{"iopub.status.busy":"2022-07-17T15:44:28.707015Z","iopub.execute_input":"2022-07-17T15:44:28.707374Z","iopub.status.idle":"2022-07-17T15:44:28.711881Z","shell.execute_reply.started":"2022-07-17T15:44:28.707340Z","shell.execute_reply":"2022-07-17T15:44:28.710996Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def make_batches(ds):\n    return (\n          ds\n          .cache()\n          .shuffle(BUFFER_SIZE)\n          .batch(BATCH_SIZE)\n          .prefetch(tf.data.AUTOTUNE))\ntrain_batches = make_batches(tf.data.Dataset.from_tensor_slices((trainX,trainY)))\nval_batches = make_batches(tf.data.Dataset.from_tensor_slices((testX,testY)))\n","metadata":{"execution":{"iopub.status.busy":"2022-07-17T15:44:28.713392Z","iopub.execute_input":"2022-07-17T15:44:28.714007Z","iopub.status.idle":"2022-07-17T15:44:28.750964Z","shell.execute_reply.started":"2022-07-17T15:44:28.713972Z","shell.execute_reply":"2022-07-17T15:44:28.750081Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def create_padding_mask(seq):\n    seq = tf.cast(tf.math.equal(seq,0),tf.float32)\n    return seq[:,tf.newaxis,tf.newaxis,:]","metadata":{"execution":{"iopub.status.busy":"2022-07-17T15:44:28.752113Z","iopub.execute_input":"2022-07-17T15:44:28.752430Z","iopub.status.idle":"2022-07-17T15:44:28.758210Z","shell.execute_reply.started":"2022-07-17T15:44:28.752395Z","shell.execute_reply":"2022-07-17T15:44:28.757109Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def create_frwrd_mask(ln):\n    mask = tfp.math.fill_triangular(tf.ones((int(ln*(ln+1)/2),),dtype=tf.int32),upper=False)\n    return mask","metadata":{"execution":{"iopub.status.busy":"2022-07-17T15:44:28.759824Z","iopub.execute_input":"2022-07-17T15:44:28.760619Z","iopub.status.idle":"2022-07-17T15:44:28.767324Z","shell.execute_reply.started":"2022-07-17T15:44:28.760582Z","shell.execute_reply":"2022-07-17T15:44:28.766427Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"class EncoderLayer(tf.keras.layers.Layer):\n    def __init__(self,d,num_heads,dff,rate=0.5):\n        super(EncoderLayer,self).__init__()\n        self.mha = tf.keras.layers.MultiHeadAttention(num_heads,key_dim=d)\n        self.ffn = tf.keras.Sequential([tf.keras.layers.Dense(dff,activation=\"relu\"),tf.keras.layers.Dense(d)])\n        self.layernorm_1 = tf.keras.layers.LayerNormalization()\n        self.layernorm_2 = tf.keras.layers.LayerNormalization()\n        self.dropout = tf.keras.layers.Dropout(rate)\n    def __call__(self,x,training,mask):\n        attn_out,attn_weights = self.mha(x,x,attention_mask=mask,return_attention_scores=True)\n        attn_out = self.dropout(attn_out,training=training)\n        out = self.layernorm_1(x+attn_out)\n        ffn_out = self.ffn(out)\n        ffn_out = self.dropout(ffn_out,training=training)\n        out = self.layernorm_2(out+ffn_out)\n        return out","metadata":{"execution":{"iopub.status.busy":"2022-07-17T15:44:28.768590Z","iopub.execute_input":"2022-07-17T15:44:28.769494Z","iopub.status.idle":"2022-07-17T15:44:28.780318Z","shell.execute_reply.started":"2022-07-17T15:44:28.769458Z","shell.execute_reply":"2022-07-17T15:44:28.779360Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"class Encoder(tf.keras.layers.Layer):\n    def __init__(self,num_layers,d,num_heads,dff,source_vocab,target_vocab,tokens=128,rate=0.5):\n        super(Encoder,self).__init__()\n        self.TOKENS=tokens\n        self.d = d\n        self.num_layers = num_layers\n        self.embedding= tf.keras.layers.Embedding(source_vocab,self.d)\n        self.pos_encod = positional_encoding(self.TOKENS,self.d)\n        self.enc_layers = [EncoderLayer(d=d,num_heads=num_heads,dff=dff,rate=rate) for _ in range(num_layers)]\n        self.dropout = tf.keras.layers.Dropout(rate)\n    def __call__(self,x,training,mask):\n        sq_len = tf.shape(x)[1]\n        x = self.embedding(x)\n        x = x+ self.pos_encod[:,:sq_len,:]\n        x= self.dropout(x,training=training)\n        for i in range(self.num_layers):\n            x = self.enc_layers[i](x,training,mask)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-07-17T15:44:28.782617Z","iopub.execute_input":"2022-07-17T15:44:28.782861Z","iopub.status.idle":"2022-07-17T15:44:28.794144Z","shell.execute_reply.started":"2022-07-17T15:44:28.782839Z","shell.execute_reply":"2022-07-17T15:44:28.793268Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"class DecoderLayer(tf.keras.layers.Layer):\n    def __init__(self,d,num_heads,dff,rate=0.5):\n        super(DecoderLayer,self).__init__()\n        self.mha_1 = tf.keras.layers.MultiHeadAttention(num_heads,key_dim=d)\n        self.mha_2 = tf.keras.layers.MultiHeadAttention(num_heads,key_dim=d)\n        self.ffn = tf.keras.Sequential([tf.keras.layers.Dense(dff,activation=\"relu\"),tf.keras.layers.Dense(d)])\n        self.layernorm_1 = tf.keras.layers.LayerNormalization()\n        self.layernorm_2 = tf.keras.layers.LayerNormalization()\n        self.layernorm_3 = tf.keras.layers.LayerNormalization()\n        self.dropout_1 = tf.keras.layers.Dropout(rate)\n        self.dropout_2 =tf.keras.layers.Dropout(rate)\n        self.dropout_3 = tf.keras.layers.Dropout(rate)\n    def __call__(self,x,enc_out,training,frwrd_mask,padding_mask):\n        attn1,attn1_weights = self.mha_1(x,x,x,frwrd_mask,return_attention_scores=True)\n        attn1 =self.dropout_1(attn1,training=training)\n        out1 = self.layernorm_1(attn1+x)\n        attn2,attn2_weights = self.mha_2(out1,enc_out,enc_out,padding_mask,return_attention_scores=True)\n        out2 = self.layernorm_2(attn2+out1)\n        ffn_out = self.ffn(out2)\n        ffn_out =  self.dropout_3(ffn_out,training=training)\n        out = self.layernorm_3(ffn_out+out2)\n        return out,attn1_weights,attn2_weights","metadata":{"execution":{"iopub.status.busy":"2022-07-17T15:44:28.795508Z","iopub.execute_input":"2022-07-17T15:44:28.796016Z","iopub.status.idle":"2022-07-17T15:44:28.809049Z","shell.execute_reply.started":"2022-07-17T15:44:28.795979Z","shell.execute_reply":"2022-07-17T15:44:28.808080Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"class Decoder(tf.keras.layers.Layer):\n    def __init__(self,num_layers,d,num_heads,dff,source_vocab,target_vocab,tokens=128,rate=0.5):\n            super(Decoder,self).__init__()\n            self.d= d \n            self.num_layers = num_layers\n            self.TOKENS=  tokens\n            self.embedding = tf.keras.layers.Embedding(target_vocab,d)\n            self.pos_encod = positional_encoding(self.TOKENS,d)\n            self.dec_layers = [DecoderLayer(d,num_heads,dff,rate) for _ in range(num_layers)]\n            self.dropout =  tf.keras.layers.Dropout(rate)\n    def __call__(self,x,enc_out,training,frwrd_mask,padding_mask):\n\n        sq_len = tf.shape(x)[1]\n        attn  ={}\n        x  = self.embedding(x)\n        x+=self.pos_encod[:,:sq_len,:]\n        x = self.dropout(x,training=training)\n        for i in range(self.num_layers):\n            x,block1,block2 = self.dec_layers[i](x,enc_out,training,frwrd_mask,padding_mask)\n            attn[f'Decoder_layer{i+1}_block1'] = block1\n            attn[f'Decoder_layer{i+1}_block2'] = block2\n        return x,attn","metadata":{"execution":{"iopub.status.busy":"2022-07-17T15:44:28.810432Z","iopub.execute_input":"2022-07-17T15:44:28.811300Z","iopub.status.idle":"2022-07-17T15:44:28.823221Z","shell.execute_reply.started":"2022-07-17T15:44:28.811265Z","shell.execute_reply":"2022-07-17T15:44:28.822069Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"class Transformer(tf.keras.Model):\n    def __init__(self,num_layers,d,num_heads,dff,source_vocab,target_vocab,tokens=128,rate=0.5):\n        super().__init__()\n        self.encoder = Encoder(num_layers,d,num_heads,dff,source_vocab,target_vocab,tokens=tokens,rate=rate)\n        self.decoder = Decoder(num_layers,d,num_heads,dff,source_vocab,target_vocab,tokens=tokens,rate=rate)\n        self.dense = tf.keras.layers.Dense(target_vocab)\n    def __call__(self,x,training):\n        inp,tar = x \n        frwrd_mask,padding_mask = self.create_mask(inp,tar)\n        enc_out = self.encoder(inp,training,padding_mask)\n        dec_out,attn = self.decoder(tar,enc_out,training,frwrd_mask,padding_mask)\n        out  = self.dense(dec_out)\n        return out,attn\n    def create_mask(self,inp,tar):\n        padding_mask = create_padding_mask(inp)\n        frwrd_mask = create_frwrd_mask(tf.shape(tar)[1])\n        dec_padding_mask = create_padding_mask(tar)\n        frwrd_mask = tf.maximum(dec_padding_mask,tf.cast(frwrd_mask,dtype=tf.float32))\n        return frwrd_mask,padding_mask","metadata":{"execution":{"iopub.status.busy":"2022-07-17T15:44:28.825265Z","iopub.execute_input":"2022-07-17T15:44:28.825991Z","iopub.status.idle":"2022-07-17T15:44:28.836972Z","shell.execute_reply.started":"2022-07-17T15:44:28.825955Z","shell.execute_reply":"2022-07-17T15:44:28.835975Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"class LearningSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n    def __init__(self,d,warmup_steps=5000):\n        super(LearningSchedule,self).__init__()\n        self.d = tf.cast(d,tf.float32)\n        self.warmup_steps= warmup_steps\n    def __call__(self,step):\n        out1 = tf.math.rsqrt(step)\n        out2 = step*(self.warmup_steps**(-1.5))\n        return tf.math.rsqrt(self.d)*tf.math.minimum(out1,out2)","metadata":{"execution":{"iopub.status.busy":"2022-07-17T15:44:28.844260Z","iopub.execute_input":"2022-07-17T15:44:28.845066Z","iopub.status.idle":"2022-07-17T15:44:28.852219Z","shell.execute_reply.started":"2022-07-17T15:44:28.845009Z","shell.execute_reply":"2022-07-17T15:44:28.851171Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Hyperparams\nnum_layers = 4\nd= 128\ndff= 1024\nnum_heads =8\ndropout= 0.1","metadata":{"execution":{"iopub.status.busy":"2022-07-17T15:44:28.853665Z","iopub.execute_input":"2022-07-17T15:44:28.854713Z","iopub.status.idle":"2022-07-17T15:44:28.861704Z","shell.execute_reply.started":"2022-07-17T15:44:28.854677Z","shell.execute_reply":"2022-07-17T15:44:28.860740Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"lr = LearningSchedule(d)\noptimizer = tf.keras.optimizers.Adam(lr)","metadata":{"execution":{"iopub.status.busy":"2022-07-17T15:44:28.863705Z","iopub.execute_input":"2022-07-17T15:44:28.864593Z","iopub.status.idle":"2022-07-17T15:44:28.872580Z","shell.execute_reply.started":"2022-07-17T15:44:28.864557Z","shell.execute_reply":"2022-07-17T15:44:28.871519Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def loss_fn(y,y_hat):\n    mask = tf.math.logical_not(tf.math.equal(y,0))\n    loss_class = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,reduction='none')\n    loss = loss_class(y,y_hat)\n    mask = tf.cast(mask,dtype=loss.dtype)\n    loss*=mask\n    return tf.reduce_sum(loss)/tf.reduce_sum(mask)","metadata":{"execution":{"iopub.status.busy":"2022-07-17T15:44:28.874047Z","iopub.execute_input":"2022-07-17T15:44:28.875130Z","iopub.status.idle":"2022-07-17T15:44:28.881783Z","shell.execute_reply.started":"2022-07-17T15:44:28.875094Z","shell.execute_reply":"2022-07-17T15:44:28.880800Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"def accuracy_fn(y,y_hat):\n    acc = tf.equal(tf.cast(y,tf.int64),tf.cast(tf.argmax(y_hat,axis=2),tf.int64))\n    mask = tf.math.logical_not(tf.math.equal(y,0))\n    acc = tf.math.logical_and(mask,acc)\n    return tf.reduce_sum(tf.cast(acc,tf.float32))/tf.reduce_sum(tf.cast(mask,tf.float32))","metadata":{"execution":{"iopub.status.busy":"2022-07-17T15:44:28.884014Z","iopub.execute_input":"2022-07-17T15:44:28.885137Z","iopub.status.idle":"2022-07-17T15:44:28.892059Z","shell.execute_reply.started":"2022-07-17T15:44:28.885099Z","shell.execute_reply":"2022-07-17T15:44:28.891092Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"train_loss = tf.keras.metrics.Mean(name='train_loss')\ntrain_accuracy = tf.keras.metrics.Mean(name='train_accuracy')\n","metadata":{"execution":{"iopub.status.busy":"2022-07-17T15:44:28.893330Z","iopub.execute_input":"2022-07-17T15:44:28.893886Z","iopub.status.idle":"2022-07-17T15:44:28.931576Z","shell.execute_reply.started":"2022-07-17T15:44:28.893849Z","shell.execute_reply":"2022-07-17T15:44:28.930719Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"model = Transformer(num_layers,d,num_heads,dff,eng_vocab_length,fra_vocab_length,rate=dropout)","metadata":{"execution":{"iopub.status.busy":"2022-07-17T15:44:28.933898Z","iopub.execute_input":"2022-07-17T15:44:28.934455Z","iopub.status.idle":"2022-07-17T15:44:29.027726Z","shell.execute_reply.started":"2022-07-17T15:44:28.934421Z","shell.execute_reply":"2022-07-17T15:44:29.026813Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"def train_step(inp,tar):\n    tar_inp = tar[:,:-1]\n    tar_real = tar[:,1:]\n    with tf.GradientTape() as tape:\n        preds,_=model([inp,tar_inp],training=True)\n        loss =loss_fn(tar_real,preds)\n    gradients = tape.gradient(loss,model.trainable_variables)\n    optimizer.apply_gradients(zip(gradients,model.trainable_variables))\n    train_loss(loss)\n    train_accuracy(accuracy_fn(tar_real, preds))\n","metadata":{"execution":{"iopub.status.busy":"2022-07-17T15:44:29.029076Z","iopub.execute_input":"2022-07-17T15:44:29.029399Z","iopub.status.idle":"2022-07-17T15:44:29.038295Z","shell.execute_reply.started":"2022-07-17T15:44:29.029366Z","shell.execute_reply":"2022-07-17T15:44:29.037180Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"with tf.device('/gpu:0'):\n    for epoch in range(20):\n        start =  time.time()\n        train_loss.reset_states()\n        train_accuracy.reset_states()\n        for (batch,(inp,tar)) in enumerate(train_batches):\n            train_step(inp,tar)\n            if batch % 50 == 0:\n                  print(f'Epoch {epoch + 1} Batch {batch} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n\n        print(f'Epoch {epoch + 1} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n        print(f'Time taken for 1 epoch: {time.time() - start:.2f} secs\\n')\n\n    ","metadata":{"execution":{"iopub.status.busy":"2022-07-17T15:44:29.039754Z","iopub.execute_input":"2022-07-17T15:44:29.040850Z","iopub.status.idle":"2022-07-17T17:15:00.718175Z","shell.execute_reply.started":"2022-07-17T15:44:29.040817Z","shell.execute_reply":"2022-07-17T17:15:00.716242Z"},"trusted":true},"execution_count":36,"outputs":[]}]}